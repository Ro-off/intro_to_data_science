{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxNOG2qiT7bb"
   },
   "source": [
    "### <Center> Лабораторна робота №6. <br> Ідентифікація користувача за допомогою логістичної регресії"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 1572,
     "status": "ok",
     "timestamp": 1600568419975,
     "user": {
      "displayName": "Москаленко В'ячеслав Васильович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64",
      "userId": "09799116143807457878"
     },
     "user_tz": -180
    },
    "id": "1_rN0IogT7be",
    "outputId": "f3fd4ebb-99b0-4f78-aecd-4239727aa1c2"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C5b5gRpT-Xz"
   },
   "source": [
    "Спочатку налаштуємо доступ до даних на google drive (якщо ви відкриваєте блокнот в google colab, а не на PC) шляхом монтування google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 15794,
     "status": "ok",
     "timestamp": 1600568453670,
     "user": {
      "displayName": "Москаленко В'ячеслав Васильович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64",
      "userId": "09799116143807457878"
     },
     "user_tz": -180
    },
    "id": "iHWvb8rCUCT8",
    "outputId": "ce3d86ef-bf7a-4055-aaa7-da328309eb7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmfAKrzDUJE9"
   },
   "source": [
    "Перевіримо шлях до папки з матеріалами лаборатоної роботи на google drive. Якщо у вас шлях відрізняється то відредагуйте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 4557,
     "status": "ok",
     "timestamp": 1600568481387,
     "user": {
      "displayName": "Москаленко В'ячеслав Васильович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64",
      "userId": "09799116143807457878"
     },
     "user_tz": -180
    },
    "id": "4dOnT8pgUF_n",
    "outputId": "6e2770e6-dadd-48b8-de5a-13f6c19064bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult.data.csv\tadult_train.csv  telecom_churn.csv  train_sessions.csv\n",
      "adult_test.csv\tsite_dic.pkl\t test_sessions.csv\n"
     ]
    }
   ],
   "source": [
    "# !ls gdrive/'My Drive'/TEACHING/IntroDataScience/intro_to_data_science/Lab_5_6/data\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyEfiPM7UPQN"
   },
   "source": [
    "Перемістимо матеріали лабораторної роботи з google drive на віртуальну машину google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "executionInfo": {
     "elapsed": 5585,
     "status": "ok",
     "timestamp": 1600568505700,
     "user": {
      "displayName": "Москаленко В'ячеслав Васильович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64",
      "userId": "09799116143807457878"
     },
     "user_tz": -180
    },
    "id": "Ab94i1fjUQGB",
    "outputId": "7b5c658c-8477-46e9-8927-67aa6a72b63d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t\tlab5_decision_trees.ipynb\n",
      "gdrive\t\t\t\tlab5_decision_trees.pdf\n",
      "lab0_intro_decision_tree.ipynb\tlab6_intruder_detection.ipynb\n",
      "lab0_intro_decision_tree.pdf\tsample_data\n"
     ]
    }
   ],
   "source": [
    "# !cp -a gdrive/'My Drive'/TEACHING/IntroDataScience/intro_to_data_science/Lab_5_6/. .\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT_YKiR6T7br"
   },
   "source": [
    "### 1. Завантаження і перетворення даних\n",
    "Дані можна самостійно завантажити за посиланням [сторінка](https://inclass.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2). Однак можна цього не робити, оскільки дані вже завантажені для проведення лабораторної роботи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "executionInfo": {
     "elapsed": 4568,
     "status": "ok",
     "timestamp": 1600568515464,
     "user": {
      "displayName": "Москаленко В'ячеслав Васильович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64",
      "userId": "09799116143807457878"
     },
     "user_tz": -180
    },
    "id": "sK2cb4cWT7bw",
    "outputId": "5a30c38e-df4f-435f-e5e8-e8178cb956d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...               time6  site7  \\\n",
       "session_id                      ...                              \n",
       "21669                      NaT  ...                 NaT    NaN   \n",
       "54843                      NaT  ...                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ... 2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ... 2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ... 2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# завантажимо навчальну і тестову вибірки\n",
    "train_df = pd.read_csv('data/train_sessions.csv',\n",
    "                       index_col='session_id')\n",
    "test_df = pd.read_csv('data/test_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "\n",
    "# приведемо колонку time1, ..., time10 до часового формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# відсортуємо дані за часом\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# подивимося на заголовок навчальної вибірки\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ycURxB3T7b5"
   },
   "source": [
    "В навчальній вибірці містяться наступні ознаки:\n",
    "    - site1 – індекс першого відвідування сайту в сесії\n",
    "    - time1 – час відвідування першого сайту в сесії\n",
    "    - ...\n",
    "    - site10 – індекс 10-го відвідування сайту в сесії\n",
    "    - time10 – час відвідування 10-го сайту в сесії\n",
    "    - target – цільова змінна, 1 для сесій Еліс, 0 для сесій інших користувачів\n",
    "    \n",
    "Сесії користувачів виділені таким чимном, щоб вони не можут бути довші півгодини чи 10 сайтів. Тобто сесія вважається закінченою або коли користувач відвідав 10 сайтів підряд або коли сесія зайняла за часом більше 30 хвилин.\n",
    "\n",
    "В таблиці зустрічаються пропущені значення, це значить, що сесія містить менше, ніж 10 сайтів. Замінимо пропущені значення нулями і приведемо ознаки до цільового типу. Також заванатажимо словник сайтів і подивимося, як він виглядає:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1600568520266,
     "user": {
      "displayName": "Москаленко В'ячеслав Васильович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64",
      "userId": "09799116143807457878"
     },
     "user_tz": -180
    },
    "id": "Q82qF45IT7b7",
    "outputId": "89b3aeb2-3590-434b-d82b-2bf4f5b91150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всього сайтів: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведемо колонки site1, ..., site10 до цілочислового формату і замінимо пропуски нулями\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "# завантажимо словник сайтів\n",
    "with open(r\"data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словника сайтів\n",
    "sites_dict_df = pd.DataFrame(list(site_dict.keys()), \n",
    "                          index=list(site_dict.values()), \n",
    "                          columns=['site'])\n",
    "print(u'всього сайтів:', sites_dict_df.shape[0])\n",
    "sites_dict_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZobaYZuT7cC"
   },
   "source": [
    "Виділимо цільову змінну і об'єднаємо вибірки, щоб разом привести їх до розрідженого формату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1b6NQLhlT7cE"
   },
   "outputs": [],
   "source": [
    "# наша цільова змінна\n",
    "y_train = train_df['target']\n",
    "\n",
    "# об'єднана таблиця вхідних даних\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# індекс, за яким будемо відокремлювати навчальну вибірку від тестової\n",
    "idx_split = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcuO-EB0T7cN"
   },
   "source": [
    "Для самої першої моделі ми використовуємо лише відвідувані сайти в сесіях (але не будемо звертати увагу на часові ознаки). В основі такого вибору даних для моделей лежить така ідея: * у Еліс є свої улюблені сайти, і якщо ви ще побачите ці сайти в сесіях, тим вище ймовірність, що це сесія Еліс і навпаки. *\n",
    "\n",
    "Підготуємо дані, з усієї таблиці виберемо лише ознаки `site1, site2, ..., site10`. Нагадуємо, що пропущені значення замінені нулем. Ось як виглядатимуть перші рядки таблиць:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1600568525949,
     "user": {
      "displayName": "Москаленко В'ячеслав Васильович",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiN6Jzqki0z69x3j5PLOje08fXCxR7L_CW7QtyNXg=s64",
      "userId": "09799116143807457878"
     },
     "user_tz": -180
    },
    "id": "Ah1VGxPDT7cP",
    "outputId": "01cb599a-27ec-462f-a677-d58532b07121"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>784</td>\n",
       "      <td>949</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>948</td>\n",
       "      <td>949</td>\n",
       "      <td>948</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "      <td>945</td>\n",
       "      <td>946</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>948</td>\n",
       "      <td>947</td>\n",
       "      <td>950</td>\n",
       "      <td>952</td>\n",
       "      <td>946</td>\n",
       "      <td>951</td>\n",
       "      <td>946</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "21669          56     55      0      0      0      0      0      0      0   \n",
       "54843          56     55     56     55      0      0      0      0      0   \n",
       "77292         946    946    951    946    946    945    948    784    949   \n",
       "114021        945    948    949    948    945    946    947    945    946   \n",
       "146670        947    950    948    947    950    952    946    951    946   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "21669            0  \n",
       "54843            0  \n",
       "77292          946  \n",
       "114021         946  \n",
       "146670         947  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# таблиця з індексами відвіданих сайтів в сесії\n",
    "full_sites = full_df[sites]\n",
    "full_sites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIocdQ-BT7cb"
   },
   "source": [
    "Сесії представляють собою послідовність індексів сайтів і дані в такому вигляді невдалі для лінійних методів. Відповідно до нашої гіпотези (у Еліс є улюблені сайти) необхідно перетворити цю таблицю таким чином, щоб кожен можливий веб-сайт відповідав своєму окремому призначенню (колонка), а його значення зростало за кількістю відвідувачів цього веб-сайту в сесіях. Це робиться в два рядки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VI3OsUzST7cc"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3Ll_cv4XT7ci"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Compressed Sparse Row matrix.\n",
      "\n",
      "This can be instantiated in several ways:\n",
      "    csr_matrix(D)\n",
      "        where D is a 2-D ndarray\n",
      "\n",
      "    csr_matrix(S)\n",
      "        with another sparse array or matrix S (equivalent to S.tocsr())\n",
      "\n",
      "    csr_matrix((M, N), [dtype])\n",
      "        to construct an empty matrix with shape (M, N)\n",
      "        dtype is optional, defaulting to dtype='d'.\n",
      "\n",
      "    csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
      "        where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
      "        relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
      "\n",
      "    csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
      "        is the standard CSR representation where the column indices for\n",
      "        row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
      "        corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
      "        If the shape parameter is not supplied, the matrix dimensions\n",
      "        are inferred from the index arrays.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "dtype : dtype\n",
      "    Data type of the matrix\n",
      "shape : 2-tuple\n",
      "    Shape of the matrix\n",
      "ndim : int\n",
      "    Number of dimensions (this is always 2)\n",
      "nnz\n",
      "size\n",
      "data\n",
      "    CSR format data array of the matrix\n",
      "indices\n",
      "    CSR format index array of the matrix\n",
      "indptr\n",
      "    CSR format index pointer array of the matrix\n",
      "has_sorted_indices\n",
      "has_canonical_format\n",
      "T\n",
      "\n",
      "Notes\n",
      "-----\n",
      "\n",
      "Sparse matrices can be used in arithmetic operations: they support\n",
      "addition, subtraction, multiplication, division, and matrix power.\n",
      "\n",
      "Advantages of the CSR format\n",
      "  - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
      "  - efficient row slicing\n",
      "  - fast matrix vector products\n",
      "\n",
      "Disadvantages of the CSR format\n",
      "  - slow column slicing operations (consider CSC)\n",
      "  - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
      "\n",
      "Canonical Format\n",
      "    - Within each row, indices are sorted by column.\n",
      "    - There are no duplicate entries.\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      ">>> import numpy as np\n",
      ">>> from scipy.sparse import csr_matrix\n",
      ">>> csr_matrix((3, 4), dtype=np.int8).toarray()\n",
      "array([[0, 0, 0, 0],\n",
      "       [0, 0, 0, 0],\n",
      "       [0, 0, 0, 0]], dtype=int8)\n",
      "\n",
      ">>> row = np.array([0, 0, 1, 2, 2, 2])\n",
      ">>> col = np.array([0, 2, 2, 0, 1, 2])\n",
      ">>> data = np.array([1, 2, 3, 4, 5, 6])\n",
      ">>> csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
      "array([[1, 0, 2],\n",
      "       [0, 0, 3],\n",
      "       [4, 5, 6]])\n",
      "\n",
      ">>> indptr = np.array([0, 2, 3, 6])\n",
      ">>> indices = np.array([0, 2, 2, 0, 1, 2])\n",
      ">>> data = np.array([1, 2, 3, 4, 5, 6])\n",
      ">>> csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
      "array([[1, 0, 2],\n",
      "       [0, 0, 3],\n",
      "       [4, 5, 6]])\n",
      "\n",
      "Duplicate entries are summed together:\n",
      "\n",
      ">>> row = np.array([0, 1, 2, 0])\n",
      ">>> col = np.array([0, 1, 1, 0])\n",
      ">>> data = np.array([1, 2, 4, 8])\n",
      ">>> csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
      "array([[9, 0, 0],\n",
      "       [0, 2, 0],\n",
      "       [0, 4, 0]])\n",
      "\n",
      "As an example of how to construct a CSR matrix incrementally,\n",
      "the following snippet builds a term-document matrix from texts:\n",
      "\n",
      ">>> docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
      ">>> indptr = [0]\n",
      ">>> indices = []\n",
      ">>> data = []\n",
      ">>> vocabulary = {}\n",
      ">>> for d in docs:\n",
      "...     for term in d:\n",
      "...         index = vocabulary.setdefault(term, len(vocabulary))\n",
      "...         indices.append(index)\n",
      "...         data.append(1)\n",
      "...     indptr.append(len(indices))\n",
      "...\n",
      ">>> csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
      "array([[2, 1, 0, 0],\n",
      "       [0, 1, 1, 1]])\n",
      "\u001b[1;31mFile:\u001b[0m           g:\\dev\\intro_to_data_science\\.venv\\lib\\site-packages\\scipy\\sparse\\_csr.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "csr_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "soTapyJpT7co"
   },
   "outputs": [],
   "source": [
    "# послідовність з індексами\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# шкана матриця\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0] + 10, 10)))[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUMiXftWT7cu"
   },
   "source": [
    "Ще один плюс використання розріджених матриць у тому, що для них є спеціальні реалізації як матричних операцій, так і алгоритми машинного навчання, що дозволяє істотно прискорити операції за рахунок особливостей структур даних. Це стосується і логістичної регресії. Ось тепер у нас все готове для побудови наших перших моделей.\n",
    "\n",
    "### 2. Побудова першої моделі\n",
    "\n",
    "Отже, у нас є алгоритм та дані для нього, побудуйте нашу першу модель, використовуючи реалізацію [логістичної регресії] (http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) з пакета ` sklearn` з параметрами за замовчуванням. Перші 90% даних будемо використовувати для навчання (навчальна вибірка, відсортована за часом), а також 10% для перевірки якості (validation).\n",
    "\n",
    "**Напишіть просту функцію, яка поверне якість моделей на вкладеній вибірці, і навчіть наш перший класифікатор**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DS4Y6Zg4T7cv"
   },
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9, seed=17):\n",
    "    '''\n",
    "    X, y – вибірка\n",
    "    ratio – у якому співвідношенні поділити вибірку\n",
    "    C, seed – коефіцієт регуляризації і random_state \n",
    "              логістичної регресії\n",
    "    '''\n",
    "    \n",
    "    # Розділимо дані на навчальну та валідаційну вибірки\n",
    "    idx = int(X.shape[0] * ratio)\n",
    "    X_train, X_valid = X[:idx, :], X[idx:, :]\n",
    "    y_train, y_valid = y[:idx], y[idx:]\n",
    "\n",
    "    # Ініціалізуємо та навчаємо модель логістичної регресії\n",
    "    logit = LogisticRegression(C=C, random_state=seed, solver='liblinear')\n",
    "    logit.fit(X_train, y_train)\n",
    "\n",
    "    # Прогнозуємо ймовірності для валідаційної вибірки\n",
    "    y_pred = logit.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    # Обчислюємо та повертаємо значення метрики ROC AUC\n",
    "    return roc_auc_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drho7H3mT7c1"
   },
   "source": [
    "**Подивіться, який отримано ROC AUC на відкладеній вибірці.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "aZgYq5eGT7c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC на відкладеній вибірці: 0.9195\n"
     ]
    }
   ],
   "source": [
    "# Обчислимо ROC AUC на відкладеній вибірці\n",
    "roc_auc = get_auc_lr_valid(full_sites_sparse[:idx_split], y_train)\n",
    "print(f'ROC AUC на відкладеній вибірці: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOcbcJt7T7c7"
   },
   "source": [
    "Будем вважати цю модель нашою першою відправною точкою (базовий рівень). Для побудови моделей для прогнозування на тестовій вибірці ** необхідно навчити модель заново вже на всій навчальній вибірці ** (покищо наша модель навчилася лише на частині даних), що підвищує її узагальнюючу здатність:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "caSGwpJNT7c8"
   },
   "outputs": [],
   "source": [
    "# функція для запису прогнозів в файлі\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnrpDV3UT7dE"
   },
   "source": [
    "**Навчіть модель на всій вибірці, зробіть прогноз для тестової вибірки і покажіть результат**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rO3SFJ87T7dF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.21002459e-03 4.81001814e-09 1.87251238e-08 2.35459752e-08\n",
      " 3.13038690e-05 2.18462626e-04 5.47933060e-04 1.32278952e-04\n",
      " 7.95194308e-04 1.03130297e-01]\n"
     ]
    }
   ],
   "source": [
    "# Ініціалізуємо та навчаємо модель логістичної регресії на всій навчальній вибірці\n",
    "logit = LogisticRegression(C=1.0, random_state=17, solver='liblinear')\n",
    "logit.fit(full_sites_sparse[:idx_split], y_train)\n",
    "\n",
    "# Робимо прогнози для тестової вибірки\n",
    "test_pred = logit.predict_proba(full_sites_sparse[idx_split:])[:, 1]\n",
    "\n",
    "# Записуємо прогнози у файл для подання\n",
    "write_to_submission_file(test_pred, 'submission.csv')\n",
    "\n",
    "# Відображаємо перші кілька прогнозів\n",
    "print(test_pred[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4rdKvt6T7dL"
   },
   "source": [
    "### 3. Покращення моделі, побудова нових ознак"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWaNbxfnT7dM"
   },
   "source": [
    "Створіть таку ознаку, яка буде представлят собою число формату ГГГГММ від тої дати, коли відбувалась сесія, наприклад 201407 -- 2014 рік і 7 месяц. Таким чином, ми будемо враховувати помісячний [линейный тренд](http://people.duke.edu/~rnau/411trend.htm) за весь період наданих даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2zT4tSJ0T7dN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time1</th>\n",
       "      <th>start_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>201301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time1  start_month\n",
       "session_id                                 \n",
       "21669      2013-01-12 08:05:57       201301\n",
       "54843      2013-01-12 08:37:23       201301\n",
       "77292      2013-01-12 08:50:13       201301\n",
       "114021     2013-01-12 08:50:17       201301\n",
       "146670     2013-01-12 08:50:20       201301"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Створимо нову ознаку 'start_month' у форматі ГГГГММ\n",
    "full_df['start_month'] = full_df['time1'].dt.year * 100 + full_df['time1'].dt.month\n",
    "\n",
    "# Відобразимо перші кілька рядків, щоб перевірити нову ознаку\n",
    "full_df[['time1', 'start_month']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXjVHoXTT7dT"
   },
   "source": [
    "Додайте нову ознаку, попередньо нормалізуючи її за допомогою `StandardScaler`, і знову підрахуйте ROC AUC на відкладеній вибірці."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jQ1Fl8aNT7dU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC з ознакою start_month: 0.9197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Нормалізуємо ознаку 'start_month'\n",
    "scaler = StandardScaler()\n",
    "start_month_scaled = scaler.fit_transform(full_df[['start_month']])\n",
    "\n",
    "# Перетворюємо нормалізовану ознаку в розріджену матрицю\n",
    "start_month_sparse = csr_matrix(start_month_scaled)\n",
    "\n",
    "# Об'єднуємо початкову розріджену матрицю з новою ознакою\n",
    "full_sites_with_month = hstack([full_sites_sparse, start_month_sparse])\n",
    "\n",
    "# Перераховуємо ROC AUC на відкладеній вибірці\n",
    "roc_auc_with_month = get_auc_lr_valid(full_sites_with_month[:idx_split], y_train)\n",
    "print(f'ROC AUC з ознакою start_month: {roc_auc_with_month:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx1-wXJ8T7dY"
   },
   "source": [
    "**Додайте дві нові ознаки: start_hour і morning.**\n",
    "\n",
    "Ознака `start_hour` - це час у якому почалася сесія (від 0 до 23), а бінарна оознака` morning` рівна 1, якщо сесія почалася вранці і 0, якщо сесія почалася пізніше (будемо вважати, що це ранок, якщо `start_hour рівний` 11 або менше).\n",
    "\n",
    "**Підрахуйте RUC AUC на відкладеній вибірці для вибірки з:**\n",
    "- сайтами, `start_month` і` start_hour`\n",
    "- сайтами, `start_month` і` morning`\n",
    "- сайтами, `start_month`,` start_hour` і `morning`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RIwOQZ8_T7da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC з ознаками start_month і start_hour: 0.9579\n",
      "ROC AUC з ознаками start_month і morning: 0.9488\n",
      "ROC AUC з ознаками start_month, start_hour і morning: 0.9592\n"
     ]
    }
   ],
   "source": [
    "# Додамо нові ознаки 'start_hour' і 'morning'\n",
    "full_df['start_hour'] = full_df['time1'].dt.hour\n",
    "full_df['morning'] = (full_df['start_hour'] <= 11).astype(int)\n",
    "\n",
    "# Нормалізуємо нові ознаки\n",
    "start_hour_scaled = scaler.fit_transform(full_df[['start_hour']])\n",
    "morning_scaled = scaler.fit_transform(full_df[['morning']])\n",
    "\n",
    "# Перетворюємо нормалізовані ознаки в розріджені матриці\n",
    "start_hour_sparse = csr_matrix(start_hour_scaled)\n",
    "morning_sparse = csr_matrix(morning_scaled)\n",
    "\n",
    "# Об'єднуємо початкову розріджену матрицю з новими ознаками\n",
    "full_sites_with_hour = hstack([full_sites_with_month, start_hour_sparse])\n",
    "full_sites_with_morning = hstack([full_sites_with_month, morning_sparse])\n",
    "full_sites_with_all = hstack([full_sites_with_month, start_hour_sparse, morning_sparse])\n",
    "\n",
    "# Перераховуємо ROC AUC на відкладеній вибірці для різних комбінацій ознак\n",
    "roc_auc_with_hour = get_auc_lr_valid(full_sites_with_hour[:idx_split], y_train)\n",
    "roc_auc_with_morning = get_auc_lr_valid(full_sites_with_morning[:idx_split], y_train)\n",
    "roc_auc_with_all = get_auc_lr_valid(full_sites_with_all[:idx_split], y_train)\n",
    "\n",
    "print(f'ROC AUC з ознаками start_month і start_hour: {roc_auc_with_hour:.4f}')\n",
    "print(f'ROC AUC з ознаками start_month і morning: {roc_auc_with_morning:.4f}')\n",
    "print(f'ROC AUC з ознаками start_month, start_hour і morning: {roc_auc_with_all:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BICIGCSsT7df"
   },
   "source": [
    "### 4. Підбір коефіцієнта регуляризації\n",
    "\n",
    "Отже, ми ввели ознаки, які покращують якість нашої моделі у порівнянні з першим бейслайном. Чи можемо ми домогтися більшого значення метрики? Після того, як ми сформували навчальну та тестову вибірки, майже завжди має сенс підібрати оптимальні гіперпараметри - характеристики моделі, які не змінюються під час навчання. Наприклад, ви вивчали вирішальні дерева, глибина дерева це гіперпараметр, а ознака, за якому відбувається розгалуження і її значення - ні. У використовуваної нами логістичної регресії ваги кожної ознаки змінюються і під час навчання знаходяться їх оптимальні значення, а коефіцієнт регуляризації залишається постійним. Це той гіперпараметр, який ми зараз будемо оптимізувати.\n",
    "\n",
    "Порахуйте якість на відкладеній вибірці з коефіцієнтом регуляризації, який за замовчуванням `C = 1 ':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zSd56_TtT7df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC на відкладеній вибірці з C=1: 0.9592\n"
     ]
    }
   ],
   "source": [
    "# Обчислимо якість на відкладеній вибірці з коефіцієнтом регуляризації C = 1\n",
    "roc_auc_default_C = get_auc_lr_valid(full_sites_with_all[:idx_split], y_train, C=1.0)\n",
    "print(f'ROC AUC на відкладеній вибірці з C=1: {roc_auc_default_C:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgyR4THVT7dm"
   },
   "source": [
    "Постараємося побити цей результат за рахунок оптимізації коефіцієнта регуляризації. Візьмемо набір можливих значень C і для кожного з них порахуємо значення метрики на відкладеної вибірці.\n",
    "\n",
    "Знайдіть `C` з` np.logspace (-3, 1, 10) `, при якому ROC AUC на відкладеної вибірці максимальний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NUex1oHvT7dm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC для C=0.001: 0.8230\n",
      "ROC AUC для C=0.0027825594022071257: 0.8965\n",
      "ROC AUC для C=0.007742636826811269: 0.9390\n",
      "ROC AUC для C=0.021544346900318832: 0.9564\n",
      "ROC AUC для C=0.05994842503189409: 0.9607\n",
      "ROC AUC для C=0.1668100537200059: 0.9612\n",
      "ROC AUC для C=0.46415888336127775: 0.9603\n",
      "ROC AUC для C=1.2915496650148828: 0.9587\n",
      "ROC AUC для C=3.593813663804626: 0.9558\n",
      "ROC AUC для C=10.0: 0.9513\n",
      "Найкраще C: 0.1668100537200059\n",
      "Найкращий ROC AUC: 0.9612\n"
     ]
    }
   ],
   "source": [
    "# Визначимо діапазон значень C для тестування\n",
    "C_values = np.logspace(-3, 1, 10)\n",
    "\n",
    "# Ініціалізуємо змінні для збереження найкращого C і відповідного ROC AUC\n",
    "best_C = None\n",
    "best_roc_auc = 0\n",
    "\n",
    "# Ітеруємо по діапазону значень C\n",
    "for C in C_values:\n",
    "    # Обчислюємо ROC AUC для поточного значення C\n",
    "    roc_auc = get_auc_lr_valid(full_sites_with_all[:idx_split], y_train, C=C)\n",
    "    print(f'ROC AUC для C={C}: {roc_auc:.4f}')\n",
    "    \n",
    "    # Оновлюємо найкраще значення C і ROC AUC, якщо поточне краще\n",
    "    if roc_auc > best_roc_auc:\n",
    "        best_C = C\n",
    "        best_roc_auc = roc_auc\n",
    "\n",
    "print(f'Найкраще C: {best_C}')\n",
    "print(f'Найкращий ROC AUC: {best_roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FA64y9S-T7ds"
   },
   "source": [
    "Нарешті, навчіть модель зі знайденим оптимальним значенням коефіцієнта регуляризації і з побудованими ознаками `start_hour`,` start_month` і `morning`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gHKSaYGpT7dt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.28563751e-04 2.85290394e-06 9.31028300e-07 6.40058664e-07\n",
      " 1.98830422e-04 7.07909326e-05 2.94006998e-03 1.85383443e-03\n",
      " 1.33196723e-04 3.15635042e-03]\n"
     ]
    }
   ],
   "source": [
    "# Ініціалізуємо та навчаємо модель логістичної регресії з оптимальним значенням C\n",
    "logit_optimal = LogisticRegression(C=best_C, random_state=17, solver='liblinear')\n",
    "logit_optimal.fit(full_sites_with_all[:idx_split], y_train)\n",
    "\n",
    "# Робимо прогнози для тестової вибірки\n",
    "test_pred_optimal = logit_optimal.predict_proba(full_sites_with_all[idx_split:])[:, 1]\n",
    "\n",
    "# Записуємо прогнози у файл для подання\n",
    "write_to_submission_file(test_pred_optimal, 'submission_optimal.csv')\n",
    "\n",
    "# Відображаємо перші кілька прогнозів\n",
    "print(test_pred_optimal[:10])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
